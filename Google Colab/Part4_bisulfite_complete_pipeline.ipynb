{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOljwWvPK9/fKnKRVCQcyt3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"TT9VgQQLhvyL"},"outputs":[],"source":["#!/usr/bin/env python3\n","\"\"\"\n","Bisulfite Conversion Efficiency Analysis Pipeline\n","Part 4: Complete Integration and Main Pipeline\n","\n","This module integrates all components and provides the main execution pipeline\n","for comprehensive bisulfite conversion efficiency analysis.\n","\"\"\"\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from datetime import datetime\n","import os\n","import json\n","import pickle\n","from pathlib import Path\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Import our custom modules (in practice, these would be separate files)\n","# from bisulfite_simulation import BisulfiteSimulator\n","# from bisulfite_metrics import ConversionEfficiencyAnalyzer, calculate_advanced_metrics\n","# from bisulfite_validation import ValidationFramework, VisualizationSuite\n","\n","class CompleteBisulfitePipeline:\n","    \"\"\"\n","    Complete integrated pipeline for bisulfite conversion efficiency analysis\n","    \"\"\"\n","\n","    def __init__(self, output_dir=\"bisulfite_analysis_results\", random_seed=42):\n","        \"\"\"\n","        Initialize the complete pipeline\n","\n","        Args:\n","            output_dir (str): Directory to save all results\n","            random_seed (int): Random seed for reproducibility\n","        \"\"\"\n","        self.output_dir = Path(output_dir)\n","        self.output_dir.mkdir(exist_ok=True)\n","\n","        # Set random seeds\n","        np.random.seed(random_seed)\n","\n","        # Initialize components\n","        self.simulator = None\n","        self.analyzer = None\n","        self.validator = ValidationFramework()\n","        self.visualizer = VisualizationSuite()\n","\n","        # Results storage\n","        self.simulation_results = {}\n","        self.analysis_results = {}\n","        self.validation_results = {}\n","        self.pipeline_metadata = {\n","            'start_time': datetime.now().isoformat(),\n","            'random_seed': random_seed,\n","            'version': '1.0.0'\n","        }\n","\n","        print(f\"Initialized Bisulfite Analysis Pipeline v{self.pipeline_metadata['version']}\")\n","        print(f\"Output directory: {self.output_dir.absolute()}\")\n","        print(f\"Random seed: {random_seed}\")\n","\n","    def run_complete_analysis(self,\n","                            genome_length=10000,\n","                            read_length=150,\n","                            coverage=30,\n","                            efficiency_range=(0.90, 0.999),\n","                            n_efficiency_points=8,\n","                            gc_content=0.42,\n","                            methylation_rates=None,\n","                            error_rate=0.001):\n","        \"\"\"\n","        Run the complete analysis pipeline\n","\n","        Args:\n","            genome_length (int): Length of simulated genome\n","            read_length (int): Sequencing read length\n","            coverage (int): Sequencing coverage depth\n","            efficiency_range (tuple): Range of conversion efficiencies to test\n","            n_efficiency_points (int): Number of efficiency points to test\n","            gc_content (float): GC content of simulated genome\n","            methylation_rates (dict): Custom methylation rates by context\n","            error_rate (float): Sequencing error rate\n","\n","        Returns:\n","            dict: Complete analysis results\n","        \"\"\"\n","        print(\"\\n\" + \"=\"*80)\n","        print(\"STARTING COMPLETE BISULFITE CONVERSION EFFICIENCY ANALYSIS\")\n","        print(\"=\"*80)\n","\n","        # Step 1: Setup and Configuration\n","        print(\"\\n1. CONFIGURATION AND SETUP\")\n","        print(\"-\" * 40)\n","\n","        config = self._setup_configuration(\n","            genome_length, read_length, coverage, efficiency_range,\n","            n_efficiency_points, gc_content, methylation_rates, error_rate\n","        )\n","\n","        # Step 2: Generate Ground Truth Data\n","        print(\"\\n2. GROUND TRUTH DATA GENERATION\")\n","        print(\"-\" * 40)\n","\n","        ground_truth = self._generate_ground_truth_data(config)\n","\n","        # Step 3: Simulate Bisulfite Sequencing Data\n","        print(\"\\n3. BISULFITE SEQUENCING SIMULATION\")\n","        print(\"-\" * 40)\n","\n","        simulation_results = self._simulate_bisulfite_data(ground_truth, config)\n","\n","        # Step 4: Analyze Conversion Efficiency\n","        print(\"\\n4. CONVERSION EFFICIENCY ANALYSIS\")\n","        print(\"-\" * 40)\n","\n","        analysis_results = self._analyze_conversion_efficiency(simulation_results, ground_truth)\n","\n","        # Step 5: Validate Results\n","        print(\"\\n5. RESULTS VALIDATION\")\n","        print(\"-\" * 40)\n","\n","        validation_results = self._validate_analysis_results(analysis_results, ground_truth)\n","\n","        # Step 6: Generate Visualizations\n","        print(\"\\n6. VISUALIZATION GENERATION\")\n","        print(\"-\" * 40)\n","\n","        visualizations = self._generate_visualizations(validation_results, analysis_results)\n","\n","        # Step 7: Create Comprehensive Report\n","        print(\"\\n7. REPORT GENERATION\")\n","        print(\"-\" * 40)\n","\n","        final_report = self._generate_final_report(\n","            config, ground_truth, analysis_results, validation_results\n","        )\n","\n","        # Step 8: Save Results\n","        print(\"\\n8. SAVING RESULTS\")\n","        print(\"-\" * 40)\n","\n","        self._save_all_results(\n","            config, ground_truth, simulation_results,\n","            analysis_results, validation_results, final_report\n","        )\n","\n","        print(\"\\n\" + \"=\"*80)\n","        print(\"ANALYSIS PIPELINE COMPLETED SUCCESSFULLY\")\n","        print(\"=\"*80)\n","\n","        return {\n","            'config': config,\n","            'ground_truth': ground_truth,\n","            'simulation_results': simulation_results,\n","            'analysis_results': analysis_results,\n","            'validation_results': validation_results,\n","            'visualizations': visualizations,\n","            'final_report': final_report,\n","            'output_directory': str(self.output_dir.absolute())\n","        }\n","\n","    def _setup_configuration(self, genome_length, read_length, coverage,\n","                           efficiency_range, n_efficiency_points, gc_content,\n","                           methylation_rates, error_rate):\n","        \"\"\"Setup and validate configuration parameters\"\"\"\n","\n","        if methylation_rates is None:\n","            methylation_rates = {\n","                'cpg_methylation_rate': 0.75,\n","                'chg_methylation_rate': 0.05,\n","                'chh_methylation_rate': 0.02\n","            }\n","\n","        # Create efficiency test points\n","        min_eff, max_eff = efficiency_range\n","        efficiency_points = self.validator.create_ground_truth_benchmarks(\n","            efficiency_range, n_efficiency_points\n","        )\n","\n","        config = {\n","            'genome_parameters': {\n","                'genome_length': genome_length,\n","                'gc_content': gc_content,\n","                'methylation_rates': methylation_rates\n","            },\n","            'sequencing_parameters': {\n","                'read_length': read_length,\n","                'coverage': coverage,\n","                'error_rate': error_rate\n","            },\n","            'efficiency_parameters': {\n","                'efficiency_range': efficiency_range,\n","                'efficiency_points': efficiency_points,\n","                'n_points': len(efficiency_points)\n","            },\n","            'analysis_parameters': {\n","                'min_coverage_threshold': 5,\n","                'bootstrap_samples': 1000,\n","                'confidence_level': 0.95,\n","                'window_size': 500\n","            }\n","        }\n","\n","        print(f\"  ✓ Genome length: {genome_length:,} bp\")\n","        print(f\"  ✓ Read parameters: {read_length} bp reads, {coverage}x coverage\")\n","        print(f\"  ✓ Testing {len(efficiency_points)} conversion efficiencies: {min_eff:.1%} - {max_eff:.1%}\")\n","        print(f\"  ✓ GC content: {gc_content:.1%}\")\n","\n","        return config\n","\n","    def _generate_ground_truth_data(self, config):\n","        \"\"\"Generate ground truth reference genome and methylation profile\"\"\"\n","\n","        # Import simulator class (in practice, would be from separate module)\n","        from bisulfite_simulation import BisulfiteSimulator\n","\n","        # Initialize simulator\n","        genome_params = config['genome_parameters']\n","        seq_params = config['sequencing_parameters']\n","\n","        self.simulator = BisulfiteSimulator(\n","            genome_length=genome_params['genome_length'],\n","            read_length=seq_params['read_length'],\n","            coverage=seq_params['coverage']\n","        )\n","\n","        # Generate reference genome\n","        reference_genome = self.simulator.generate_reference_genome(\n","            gc_content=genome_params['gc_content']\n","        )\n","\n","        # Generate methylation profile\n","        methylation_profile = self.simulator.generate_methylation_profile(\n","            **genome_params['methylation_rates']\n","        )\n","\n","        # Calculate ground truth statistics\n","        stats = self._calculate_ground_truth_statistics(reference_genome, methylation_profile)\n","\n","        ground_truth = {\n","            'reference_genome': reference_genome,\n","            'methylation_profile': methylation_profile,\n","            'statistics': stats,\n","            'simulator': self.simulator\n","        }\n","\n","        print(f\"  ✓ Generated {len(reference_genome):,} bp reference genome\")\n","        print(f\"  ✓ Created methylation profile for {len(methylation_profile):,} cytosines\")\n","        print(f\"  ✓ Ground truth statistics calculated\")\n","\n","        return ground_truth\n","\n","    def _calculate_ground_truth_statistics(self, reference_genome, methylation_profile):\n","        \"\"\"Calculate comprehensive statistics for ground truth data\"\"\"\n","\n","        # Basic composition statistics\n","        composition = {\n","            'A': reference_genome.count('A'),\n","            'T': reference_genome.count('T'),\n","            'G': reference_genome.count('G'),\n","            'C': reference_genome.count('C')\n","        }\n","\n","        total_bases = len(reference_genome)\n","        composition_pct = {base: count/total_bases for base, count in composition.items()}\n","\n","        # Methylation statistics by context\n","        context_stats = {}\n","        for context in ['CpG', 'CHG', 'CHH']:\n","            context_positions = [pos for pos, data in methylation_profile.items()\n","                               if data['context'] == context]\n","            methylated_positions = [pos for pos in context_positions\n","                                  if methylation_profile[pos]['is_methylated']]\n","\n","            context_stats[context] = {\n","                'total_sites': len(context_positions),\n","                'methylated_sites': len(methylated_positions),\n","                'methylation_rate': len(methylated_positions) / len(context_positions) if context_positions else 0\n","            }\n","\n","        # CpG island analysis (simplified)\n","        cpg_density = self._calculate_cpg_density(reference_genome)\n","\n","        return {\n","            'composition': composition,\n","            'composition_percentages': composition_pct,\n","            'context_statistics': context_stats,\n","            'cpg_density': cpg_density,\n","            'total_cytosines': len(methylation_profile),\n","            'genome_length': len(reference_genome)\n","        }\n","\n","    def _calculate_cpg_density(self, sequence, window_size=100):\n","        \"\"\"Calculate CpG density across the genome\"\"\"\n","        densities = []\n","\n","        for i in range(0, len(sequence) - window_size, window_size):\n","            window = sequence[i:i+window_size]\n","            cpg_count = window.count('CG')\n","            c_count = window.count('C')\n","            g_count = window.count('G')\n","\n","            # CpG density = observed CpG / expected CpG\n","            expected_cpg = (c_count * g_count) / len(window) if len(window) > 0 else 0\n","            density = cpg_count / expected_cpg if expected_cpg > 0 else 0\n","            densities.append(density)\n","\n","        return {\n","            'mean_density': np.mean(densities),\n","            'std_density': np.std(densities),\n","            'densities': densities\n","        }\n","\n","    def _simulate_bisulfite_data(self, ground_truth, config):\n","        \"\"\"Simulate bisulfite sequencing data for different conversion efficiencies\"\"\"\n","\n","        efficiency_points = config['efficiency_parameters']['efficiency_points']\n","        seq_params = config['sequencing_parameters']\n","\n","        simulation_results = {}\n","\n","        for i, efficiency in enumerate(efficiency_points):\n","            print(f\"  Simulating efficiency {i+1}/{len(efficiency_points)}: {efficiency:.1%}\")\n","\n","            # Simulate bisulfite conversion\n","            converted_genome = self.simulator.simulate_bisulfite_conversion(\n","                conversion_efficiency=efficiency,\n","                incomplete_conversion_bias={'CpG': 1.0, 'CHG': 0.9, 'CHH': 0.8}\n","            )\n","\n","            # Generate sequencing reads\n","            reads = self.simulator.generate_sequencing_reads(\n","                converted_genome,\n","                error_rate=seq_params['error_rate']\n","            )\n","\n","            # Store simulation data\n","            simulation_results[efficiency] = {\n","                'converted_genome': converted_genome,\n","                'reads': reads,\n","                'conversion_events': self.simulator.conversion_events.copy(),\n","                'true_efficiency': efficiency,\n","                'read_statistics': self._calculate_read_statistics(reads)\n","            }\n","\n","        print(f\"  ✓ Simulated {len(efficiency_points)} datasets\")\n","        print(f\"  ✓ Total reads generated: {sum(len(data['reads']) for data in simulation_results.values()):,}\")\n","\n","        return simulation_results\n","\n","    def _calculate_read_statistics(self, reads):\n","        \"\"\"Calculate statistics for generated reads\"\"\"\n","\n","        if not reads:\n","            return {}\n","\n","        lengths = [read['length'] for read in reads]\n","        start_positions = [read['start_pos'] for read in reads]\n","\n","        return {\n","            'total_reads': len(reads),\n","            'mean_length': np.mean(lengths),\n","            'std_length': np.std(lengths),\n","            'min_length': np.min(lengths),\n","            'max_length': np.max(lengths),\n","            'coverage_start': np.min(start_positions),\n","            'coverage_end': np.max([read['end_pos'] for read in reads]),\n","            'mean_start_pos': np.mean(start_positions)\n","        }\n","\n","    def _analyze_conversion_efficiency(self, simulation_results, ground_truth):\n","        \"\"\"Analyze conversion efficiency using multiple methods\"\"\"\n","\n","        # Import analyzer class\n","        from bisulfite_metrics import ConversionEfficiencyAnalyzer, calculate_advanced_metrics\n","\n","        self.analyzer = ConversionEfficiencyAnalyzer()\n","\n","        reference_genome = ground_truth['reference_genome']\n","        methylation_profile = ground_truth['methylation_profile']\n","\n","        analysis_results = {}\n","\n","        for efficiency, sim_data in simulation_results.items():\n","            print(f\"  Analyzing {efficiency:.1%} efficiency dataset...\")\n","\n","            reads = sim_data['reads']\n","\n","            # Primary analysis\n","            primary_analysis = self.analyzer.analyze_reads(\n","                reads=reads,\n","                reference_genome=reference_genome,\n","                methylation_profile=methylation_profile,\n","                true_efficiency=efficiency\n","            )\n","\n","            # Advanced metrics\n","            advanced_metrics = calculate_advanced_metrics(\n","                reads=reads,\n","                reference_genome=reference_genome,\n","                methylation_profile=methylation_profile,\n","                conversion_events=sim_data['conversion_events']\n","            )\n","\n","            # Performance benchmarking\n","            performance_metrics = self._calculate_performance_metrics(\n","                primary_analysis, efficiency\n","            )\n","\n","            # Combine all analysis results\n","            analysis_results[efficiency] = {\n","                'primary_analysis': primary_analysis,\n","                'advanced_metrics': advanced_metrics,\n","                'performance_metrics': performance_metrics,\n","                'dataset_info': {\n","                    'true_efficiency': efficiency,\n","                    'total_reads': len(reads),\n","                    'conversion_events': len(sim_data['conversion_events'])\n","                }\n","            }\n","\n","        print(f\"  ✓ Analyzed {len(analysis_results)} datasets\")\n","        print(f\"  ✓ Applied {len(['non_cpg', 'lambda_dna', 'chh', 'confidence_interval'])} efficiency measurement methods\")\n","\n","        return analysis_results\n","\n","    def _calculate_performance_metrics(self, analysis, true_efficiency):\n","        \"\"\"Calculate performance metrics for each analysis method\"\"\"\n","\n","        methods = ['non_cpg_efficiency', 'lambda_efficiency', 'chh_efficiency']\n","        performance = {}\n","\n","        for method in methods:\n","            method_data = analysis.get(method, {})\n","            estimated_eff = method_data.get('efficiency')\n","\n","            if estimated_eff is not None:\n","                error = abs(estimated_eff - true_efficiency)\n","                relative_error = error / true_efficiency if true_efficiency > 0 else float('inf')\n","                bias = estimated_eff - true_efficiency\n","\n","                performance[method] = {\n","                    'estimated_efficiency': estimated_eff,\n","                    'absolute_error': error,\n","                    'relative_error': relative_error,\n","                    'bias': bias,\n","                    'sample_size': method_data.get('total_sites', 0)\n","                }\n","\n","        # Confidence interval performance\n","        ci_data = analysis.get('confidence_intervals', {})\n","        if 'mean_efficiency' in ci_data:\n","            estimated_eff = ci_data['mean_efficiency']\n","            ci_lower, ci_upper = ci_data.get('confidence_interval', (None, None))\n","\n","            performance['confidence_interval'] = {\n","                'estimated_efficiency': estimated_eff,\n","                'absolute_error': abs(estimated_eff - true_efficiency),\n","                'relative_error': abs(estimated_eff - true_efficiency) / true_efficiency,\n","                'bias': estimated_eff - true_efficiency,\n","                'contains_true_value': ci_lower <= true_efficiency <= ci_upper if ci_lower and ci_upper else False,\n","                'interval_width': ci_upper - ci_lower if ci_lower and ci_upper else None\n","            }\n","\n","        return performance\n","\n","    def _validate_analysis_results(self, analysis_results, ground_truth):\n","        \"\"\"Comprehensive validation of analysis results\"\"\"\n","\n","        # Extract data for validation\n","        true_efficiencies = list(analysis_results.keys())\n","\n","        # Restructure analysis results for validation framework\n","        validation_input = {}\n","        for efficiency, results in analysis_results.items():\n","            primary = results['primary_analysis']\n","\n","            validation_input[efficiency] = {\n","                'non_cpg_efficiency': primary.get('non_cpg_efficiency', {}),\n","                'lambda_efficiency': primary.get('lambda_efficiency', {}),\n","                'chh_efficiency': primary.get('chh_efficiency', {}),\n","                'confidence_intervals': primary.get('confidence_intervals', {}),\n","                'summary_metrics': primary.get('summary_metrics', {})\n","            }\n","\n","        # Run validation\n","        validation_results = self.validator.validate_method_accuracy(\n","            validation_input, true_efficiencies\n","        )\n","\n","        # Add custom validation metrics\n","        custom_validation = self._perform_custom_validation(analysis_results, ground_truth)\n","        validation_results['custom_metrics'] = custom_validation\n","\n","        print(f\"  ✓ Validated {len(true_efficiencies)} efficiency measurements\")\n","        print(f\"  ✓ Analyzed {len([k for k in validation_results.keys() if k != 'consistency_analysis'])} methods\")\n","\n","        return validation_results\n","\n","    def _perform_custom_validation(self, analysis_results, ground_truth):\n","        \"\"\"Perform custom validation specific to bisulfite analysis\"\"\"\n","\n","        # 1. Context-specific accuracy analysis\n","        context_accuracy = self._validate_context_specific_accuracy(analysis_results)\n","\n","        # 2. Coverage-dependent performance\n","        coverage_performance = self._validate_coverage_dependence(analysis_results)\n","\n","        # 3. Efficiency range sensitivity\n","        range_sensitivity = self._validate_efficiency_range_sensitivity(analysis_results)\n","\n","        # 4. Method stability analysis\n","        stability_analysis = self._validate_method_stability(analysis_results)\n","\n","        return {\n","            'context_accuracy': context_accuracy,\n","            'coverage_performance': coverage_performance,\n","            'range_sensitivity': range_sensitivity,\n","            'stability_analysis': stability_analysis\n","        }\n","\n","    def _validate_context_specific_accuracy(self, analysis_results):\n","        \"\"\"Validate accuracy for different cytosine contexts\"\"\"\n","\n","        context_performance = {'CpG': [], 'CHG': [], 'CHH': []}\n","\n","        for efficiency, results in analysis_results.items():\n","            context_analysis = results['primary_analysis'].get('context_analysis', {})\n","\n","            for context, data in context_analysis.items():\n","                if context in context_performance and 'efficiency' in data:\n","                    estimated = data['efficiency']\n","                    error = abs(estimated - efficiency)\n","                    context_performance[context].append(error)\n","\n","        # Calculate statistics for each context\n","        context_stats = {}\n","        for context, errors in context_performance.items():\n","            if errors:\n","                context_stats[context] = {\n","                    'mean_error': np.mean(errors),\n","                    'std_error': np.std(errors),\n","                    'max_error': np.max(errors),\n","                    'n_samples': len(errors)\n","                }\n","\n","        return context_stats\n","\n","    def _validate_coverage_dependence(self, analysis_results):\n","        \"\"\"Analyze how method performance depends on sequencing coverage\"\"\"\n","\n","        coverage_data = []\n","\n","        for efficiency, results in analysis_results.items():\n","            dataset_info = results['dataset_info']\n","            performance = results['performance_metrics']\n","\n","            total_reads = dataset_info['total_reads']\n","\n","            for method, perf_data in performance.items():\n","                if 'absolute_error' in perf_data:\n","                    coverage_data.append({\n","                        'method': method,\n","                        'coverage': total_reads,\n","                        'error': perf_data['absolute_error'],\n","                        'efficiency': efficiency\n","                    })\n","\n","        # Group by method and calculate coverage-error correlation\n","        coverage_analysis = {}\n","        methods = set(row['method'] for row in coverage_data)\n","\n","        for method in methods:\n","            method_data = [row for row in coverage_data if row['method'] == method]\n","            if len(method_data) >= 3:\n","                coverages = [row['coverage'] for row in method_data]\n","                errors = [row['error'] for row in method_data]\n","\n","                correlation = np.corrcoef(coverages, errors)[0,1] if len(coverages) > 1 else 0\n","\n","                coverage_analysis[method] = {\n","                    'coverage_error_correlation': correlation,\n","                    'mean_error': np.mean(errors),\n","                    'n_points': len(method_data)\n","                }\n","\n","        return coverage_analysis\n","\n","    def _validate_efficiency_range_sensitivity(self, analysis_results):\n","        \"\"\"Analyze method performance across different efficiency ranges\"\"\"\n","\n","        efficiencies = sorted(analysis_results.keys())\n","\n","        # Define efficiency ranges\n","        ranges = {\n","            'low': [e for e in efficiencies if e < 0.95],\n","            'medium': [e for e in efficiencies if 0.95 <= e < 0.99],\n","            'high': [e for e in efficiencies if e >= 0.99]\n","        }\n","\n","        range_performance = {}\n","\n","        for range_name, range_effs in ranges.items():\n","            if not range_effs:\n","                continue\n","\n","            range_errors = {}\n","\n","            for efficiency in range_effs:\n","                performance = analysis_results[efficiency]['performance_metrics']\n","\n","                for method, perf_data in performance.items():\n","                    if method not in range_errors:\n","                        range_errors[method] = []\n","\n","                    if 'absolute_error' in perf_data:\n","                        range_errors[method].append(perf_data['absolute_error'])\n","\n","            # Calculate statistics for each method in this range\n","            range_stats = {}\n","            for method, errors in range_errors.items():\n","                if errors:\n","                    range_stats[method] = {\n","                        'mean_error': np.mean(errors),\n","                        'std_error': np.std(errors),\n","                        'max_error': np.max(errors),\n","                        'n_samples': len(errors)\n","                    }\n","\n","            range_performance[range_name] = range_stats\n","\n","        return range_performance\n","\n","    def _validate_method_stability(self, analysis_results):\n","        \"\"\"Analyze stability and consistency of methods across conditions\"\"\"\n","\n","        # Calculate coefficient of variation for each method across all efficiencies\n","        method_stability = {}\n","\n","        methods = ['non_cpg_efficiency', 'lambda_efficiency', 'chh_efficiency', 'confidence_interval']\n","\n","        for method in methods:\n","            errors = []\n","            biases = []\n","\n","            for efficiency, results in analysis_results.items():\n","                perf_data = results['performance_metrics'].get(method, {})\n","\n","                if 'absolute_error' in perf_data:\n","                    errors.append(perf_data['absolute_error'])\n","                if 'bias' in perf_data:\n","                    biases.append(perf_data['bias'])\n","\n","            if errors:\n","                method_stability[method] = {\n","                    'error_cv': np.std(errors) / np.mean(errors) if np.mean(errors) > 0 else float('inf'),\n","                    'mean_error': np.mean(errors),\n","                    'error_range': np.max(errors) - np.min(errors),\n","                    'bias_consistency': np.std(biases) if biases else 0,\n","                    'n_measurements': len(errors)\n","                }\n","\n","        return method_stability\n","\n","    def _generate_visualizations(self, validation_results, analysis_results):\n","        \"\"\"Generate comprehensive visualizations\"\"\"\n","\n","        print(\"  Creating validation plots...\")\n","        figures = self.visualizer.create_accuracy_plots(\n","            validation_results,\n","            save_path=str(self.output_dir / \"validation_plots\")\n","        )\n","\n","        print(\"  Creating analysis summary plots...\")\n","        summary_figures = self._create_analysis_summary_plots(analysis_results)\n","\n","        print(\"  Creating method comparison plots...\")\n","        comparison_figures = self._create_method_comparison_plots(analysis_results, validation_results)\n","\n","        all_figures = {\n","            'validation_plots': figures,\n","            'summary_plots': summary_figures,\n","            'comparison_plots': comparison_figures\n","        }\n","\n","        print(f\"  ✓ Generated {sum(len(figs) for figs in all_figures.values())} visualization panels\")\n","\n","        return all_figures\n","\n","    def _create_analysis_summary_plots(self, analysis_results):\n","        \"\"\"Create summary plots showing analysis results\"\"\"\n","\n","        # Extract data for plotting\n","        efficiencies = sorted(analysis_results.keys())\n","\n","        # Plot 1: Efficiency estimation accuracy\n","        fig1, ax1 = plt.subplots(figsize=(12, 8))\n","\n","        methods = ['non_cpg_efficiency', 'lambda_efficiency', 'chh_efficiency']\n","        method_labels = ['Non-CpG', 'Lambda DNA', 'CHH Context']\n","        colors = ['blue', 'red', 'green']\n","\n","        for method, label, color in zip(methods, method_labels, colors):\n","            estimated_effs = []\n","            for eff in efficiencies:\n","                est = analysis_results[eff]['primary_analysis'].get(method, {}).get('efficiency')\n","                estimated_effs.append(est if est is not None else np.nan)\n","\n","            ax1.plot(efficiencies, estimated_effs, 'o-', label=label, color=color,\n","                    linewidth=2, markersize=6)\n","\n","        # Perfect prediction line\n","        ax1.plot(efficiencies, efficiencies, 'k--', alpha=0.5, label='Perfect Prediction')\n","\n","        ax1.set_xlabel('True Conversion Efficiency')\n","        ax1.set_ylabel('Estimated Conversion Efficiency')\n","        ax1.set_title('Conversion Efficiency Estimation Accuracy')\n","        ax1.legend()\n","        ax1.grid(True, alpha=0.3)\n","\n","        # Plot 2: Method error comparison\n","        fig2, ax2 = plt.subplots(figsize=(12, 6))\n","\n","        method_errors = {method: [] for method in methods}\n","\n","        for eff in efficiencies:\n","            for method in methods:\n","                perf_data = analysis_results[eff]['performance_metrics'].get(method, {})\n","                error = perf_data.get('absolute_error')\n","                method_errors[method].append(error if error is not None else np.nan)\n","\n","        x_pos = np.arange(len(efficiencies))\n","        width = 0.25\n","\n","        for i, (method, label, color) in enumerate(zip(methods, method_labels, colors)):\n","            offset = (i - 1) * width\n","            ax2.bar(x_pos + offset, method_errors[method], width,\n","                   label=label, color=color, alpha=0.7)\n","\n","        ax2.set_xlabel('True Conversion Efficiency')\n","        ax2.set_ylabel('Absolute Error')\n","        ax2.set_title('Method Error Comparison Across Efficiency Range')\n","        ax2.set_xticks(x_pos)\n","        ax2.set_xticklabels([f'{eff:.1%}' for eff in efficiencies], rotation=45)\n","        ax2.legend()\n","        ax2.grid(True, alpha=0.3)\n","\n","        return {'efficiency_accuracy': fig1, 'error_comparison': fig2}\n","\n","    def _create_method_comparison_plots(self, analysis_results, validation_results):\n","        \"\"\"Create detailed method comparison visualizations\"\"\"\n","\n","        # Plot 1: Performance metrics radar chart\n","        fig1, ax1 = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))\n","\n","        methods = [k for k in validation_results.keys() if k != 'consistency_analysis']\n","        metrics = ['r2_score', 'mae', 'mape', 'within_2pct_accuracy']\n","        metric_labels = ['R² Score', 'MAE', 'MAPE (%)', '±2% Accuracy (%)']\n","\n","        # Normalize metrics for radar plot\n","        angles = np.linspace(0, 2 * np.pi, len(metrics), endpoint=False).tolist()\n","        angles += angles[:1]  # Complete the circle\n","\n","        colors = plt.cm.Set3(np.linspace(0, 1, len(methods)))\n","\n","        for i, method in enumerate(methods):\n","            if method in validation_results:\n","                data = validation_results[method]\n","                values = [\n","                    data.get('r2_score', 0),\n","                    1 - data.get('mae', 1),  # Invert MAE (higher is better)\n","                    1 - data.get('mape', 100) / 100,  # Invert MAPE\n","                    data.get('within_2pct_accuracy', 0) / 100\n","                ]\n","                values += values[:1]  # Complete the circle\n","\n","                ax1.plot(angles, values, 'o-', linewidth=2,\n","                        label=method.replace('_', ' ').title(), color=colors[i])\n","                ax1.fill(angles, values, alpha=0.25, color=colors[i])\n","\n","        ax1.set_xticks(angles[:-1])\n","        ax1.set_xticklabels(metric_labels)\n","        ax1.set_ylim(0, 1)\n","        ax1.set_title('Method Performance Comparison\\n(Radar Chart)', pad=20)\n","        ax1.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))\n","\n","        return {'performance_radar': fig1}\n","\n","    def _generate_final_report(self, config, ground_truth, analysis_results, validation_results):\n","        \"\"\"Generate comprehensive final report\"\"\"\n","\n","        print(\"  Creating comprehensive analysis report...\")\n","\n","        # Basic validation report\n","        basic_report = self.visualizer.create_comprehensive_report(validation_results)\n","\n","        # Extended analysis report\n","        extended_report = self._create_extended_report(config, ground_truth, analysis_results, validation_results)\n","\n","        # Combine reports\n","        final_report = f\"\"\"\n","{basic_report}\n","\n","{extended_report}\n","        \"\"\"\n","\n","        return final_report.strip()\n","\n","    def _create_extended_report(self, config, ground_truth, analysis_results, validation_results):\n","        \"\"\"Create extended analysis report with additional insights\"\"\"\n","\n","        report = []\n","        report.append(\"\\n\" + \"=\"*80)\n","        report.append(\"EXTENDED ANALYSIS REPORT\")\n","        report.append(\"=\"*80)\n","\n","        # Configuration summary\n","        report.append(\"\\nANALYSIS CONFIGURATION\")\n","        report.append(\"-\"*40)\n","        genome_params = config['genome_parameters']\n","        seq_params = config['sequencing_parameters']\n","        eff_params = config['efficiency_parameters']\n","\n","        report.append(f\"Genome length: {genome_params['genome_length']:,} bp\")\n","        report.append(f\"GC content: {genome_params['gc_content']:.1%}\")\n","        report.append(f\"Read length: {seq_params['read_length']} bp\")\n","        report.append(f\"Coverage: {seq_params['coverage']}x\")\n","        report.append(f\"Sequencing error rate: {seq_params['error_rate']:.1%}\")\n","        report.append(f\"Efficiency range tested: {eff_params['efficiency_range'][0]:.1%} - {eff_params['efficiency_range'][1]:.1%}\")\n","        report.append(f\"Number of test points: {eff_params['n_points']}\")\n","\n","        # Ground truth statistics\n","        report.append(\"\\nGROUND TRUTH STATISTICS\")\n","        report.append(\"-\"*40)\n","        stats = ground_truth['statistics']\n","\n","        report.append(\"Nucleotide composition:\")\n","        for base, pct in stats['composition_percentages'].items():\n","            count = stats['composition'][base]\n","            report.append(f\"  {base}: {count:,} ({pct:.1%})\")\n","\n","        report.append(\"\\nMethylation by context:\")\n","        for context, context_stats in stats['context_statistics'].items():\n","            total = context_stats['total_sites']\n","            methylated = context_stats['methylated_sites']\n","            rate = context_stats['methylation_rate']\n","            report.append(f\"  {context}: {methylated:,}/{total:,} ({rate:.1%})\")\n","\n","        # Analysis performance summary\n","        report.append(\"\\nANALYSIS PERFORMANCE SUMMARY\")\n","        report.append(\"-\"*40)\n","\n","        # Best and worst performing conditions\n","        best_conditions = []\n","        worst_conditions = []\n","\n","        for efficiency, results in analysis_results.items():\n","            consensus_error = 0\n","            n_methods = 0\n","\n","            for method, perf_data in results['performance_metrics'].items():\n","                if 'absolute_error' in perf_data:\n","                    consensus_error += perf_data['absolute_error']\n","                    n_methods += 1\n","\n","            if n_methods > 0:\n","                avg_error = consensus_error / n_methods\n","                best_conditions.append((efficiency, avg_error))\n","                worst_conditions.append((efficiency, avg_error))\n","\n","        best_conditions.sort(key=lambda x: x[1])\n","        worst_conditions.sort(key=lambda x: x[1], reverse=True)\n","\n","        if best_conditions:\n","            best_eff, best_err = best_conditions[0]\n","            report.append(f\"Best performance: {best_eff:.1%} efficiency (avg error: {best_err:.6f})\")\n","\n","        if worst_conditions:\n","            worst_eff, worst_err = worst_conditions[0]\n","            report.append(f\"Most challenging: {worst_eff:.1%} efficiency (avg error: {worst_err:.6f})\")\n","\n","        # Custom validation insights\n","        custom_metrics = validation_results.get('custom_metrics', {})\n","\n","        if 'range_sensitivity' in custom_metrics:\n","            report.append(\"\\nEFFICIENCY RANGE SENSITIVITY\")\n","            report.append(\"-\"*40)\n","\n","            range_perf = custom_metrics['range_sensitivity']\n","            for range_name, methods in range_perf.items():\n","                report.append(f\"{range_name.title()} efficiency range:\")\n","                for method, stats in methods.items():\n","                    mean_err = stats['mean_error']\n","                    n_samples = stats['n_samples']\n","                    method_clean = method.replace('_', ' ').title()\n","                    report.append(f\"  {method_clean}: {mean_err:.6f} avg error (n={n_samples})\")\n","\n","        # Recommendations and conclusions\n","        report.append(\"\\nRECOMMENDATIONS AND CONCLUSIONS\")\n","        report.append(\"-\"*40)\n","\n","        # Find most reliable method\n","        method_reliability = {}\n","        for method, validation_data in validation_results.items():\n","            if method != 'consistency_analysis' and 'r2_score' in validation_data:\n","                r2 = validation_data['r2_score']\n","                mae = validation_data['mae']\n","                within_2pct = validation_data.get('within_2pct_accuracy', 0)\n","\n","                # Composite reliability score\n","                reliability = (r2 + (1 - mae) + within_2pct/100) / 3\n","                method_reliability[method] = reliability\n","\n","        if method_reliability:\n","            best_method = max(method_reliability.items(), key=lambda x: x[1])\n","            report.append(f\"Most reliable method: {best_method[0].replace('_', ' ').title()} \"\n","                         f\"(reliability score: {best_method[1]:.3f})\")\n","\n","        # Analysis limitations and considerations\n","        report.append(\"\\nLIMITATIONS AND CONSIDERATIONS\")\n","        report.append(\"-\"*40)\n","        report.append(\"• Simulation assumes uniform error rates across genome\")\n","        report.append(\"• Real bisulfite data may have additional biases not modeled\")\n","        report.append(\"• Method performance may vary with different methylation patterns\")\n","        report.append(\"• Coverage uniformity assumed - real data may have coverage bias\")\n",""]}]}